{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26a6ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_nn: (16661, 98)\n",
      "X_test_nn : (4166, 98)\n",
      "y_train_nn: (16661,)\n",
      "y_test_nn : (4166,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargo la base limpia que ya se había generado en la etapa de preprocesamiento\n",
    "df = pd.read_csv(\"df_cleaned.csv\")\n",
    "\n",
    "# Defino el target del modelo 2 como el logaritmo natural del precio\n",
    "# (mismo target conceptual del modelo 1, pero acá lo optimizamos para desempeño)\n",
    "y_nn = np.log(df[\"price\"])\n",
    "\n",
    "# Tomo solo las columnas numéricas como variables de entrada\n",
    "# (incluye dummies y variables binarias que creamos antes)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Quito la columna de precio de las variables explicativas para no predecirnos a nosotros mismos\n",
    "feature_cols_nn = [col for col in numeric_cols if col != \"price\"]\n",
    "\n",
    "X_nn = df[feature_cols_nn].copy()\n",
    "\n",
    "# Parto los datos en entrenamiento y prueba para poder evaluar bien la red\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(\n",
    "    X_nn,\n",
    "    y_nn,\n",
    "    test_size=0.2,\n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "# Convierto a float32 y a matrices de numpy porque así trabaja mejor TensorFlow/Keras\n",
    "X_train_nn = X_train_nn.astype(\"float32\").values\n",
    "X_test_nn = X_test_nn.astype(\"float32\").values\n",
    "y_train_nn = y_train_nn.astype(\"float32\").values\n",
    "y_test_nn = y_test_nn.astype(\"float32\").values\n",
    "\n",
    "# Reviso tamaños para confirmar que todo quedó bien armado\n",
    "print(\"X_train_nn:\", X_train_nn.shape)\n",
    "print(\"X_test_nn :\", X_test_nn.shape)\n",
    "print(\"y_train_nn:\", y_train_nn.shape)\n",
    "print(\"y_test_nn :\", y_test_nn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m)             │           \u001b[38;5;34m197\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,758</span> (42.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,758\u001b[0m (42.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,561</span> (41.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,561\u001b[0m (41.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197</span> (792.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m197\u001b[0m (792.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import setuptools.dist  # en algunas versiones de Python esto evita problemas al importar tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fijo semillas para que los resultados sean lo más reproducibles posible\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# Dimensión de entrada para la red (tantas neuronas como columnas en X)\n",
    "input_dim = X_train_nn.shape[1]\n",
    "\n",
    "# Capa de normalización: aprende media y desviación de las variables de entrada\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_train_nn)\n",
    "\n",
    "def build_mlp_model(\n",
    "    n_hidden_layers=2,\n",
    "    units_per_layer=64,\n",
    "    dropout_rate=0.10,\n",
    "    learning_rate=0.001\n",
    "):\n",
    "    \"\"\"\n",
    "    Se pasan como argumentos para poder probar varias configuraciones después.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Entrada + normalización de todas las variables explicativas\n",
    "    model.add(tf.keras.Input(shape=(input_dim,)))\n",
    "    model.add(normalizer)\n",
    "    \n",
    "    # Capas ocultas densas con ReLU\n",
    "    for _ in range(n_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(units_per_layer, activation=\"relu\"))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Capa de salida con un solo valor: predicción de log(price)\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    # Optimizador Adam con tasa de aprendizaje configurable\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Uso mean_absolute_error como función de pérdida y métrica principal\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mean_absolute_error\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Construyo un primer modelo base para revisar que todo esté bien conectado\n",
    "baseline_model = build_mlp_model(\n",
    "    n_hidden_layers=2,\n",
    "    units_per_layer=64,\n",
    "    dropout_rate=0.10,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "baseline_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d63e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.7878 - mean_absolute_error: 2.7878 - val_loss: 0.9499 - val_mean_absolute_error: 0.9499\n",
      "Epoch 2/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9074 - mean_absolute_error: 0.9074 - val_loss: 0.5933 - val_mean_absolute_error: 0.5933\n",
      "Epoch 3/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7303 - mean_absolute_error: 0.7303 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841\n",
      "Epoch 4/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6698 - mean_absolute_error: 0.6698 - val_loss: 0.4457 - val_mean_absolute_error: 0.4457\n",
      "Epoch 5/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6291 - mean_absolute_error: 0.6291 - val_loss: 0.4105 - val_mean_absolute_error: 0.4105\n",
      "Epoch 6/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5949 - mean_absolute_error: 0.5949 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 7/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5697 - mean_absolute_error: 0.5697 - val_loss: 0.3870 - val_mean_absolute_error: 0.3870\n",
      "Epoch 8/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5500 - mean_absolute_error: 0.5500 - val_loss: 0.3745 - val_mean_absolute_error: 0.3745\n",
      "Epoch 9/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5342 - mean_absolute_error: 0.5342 - val_loss: 0.3675 - val_mean_absolute_error: 0.3675\n",
      "Epoch 10/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5321 - mean_absolute_error: 0.5321 - val_loss: 0.3725 - val_mean_absolute_error: 0.3725\n",
      "Epoch 11/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5207 - mean_absolute_error: 0.5207 - val_loss: 0.3647 - val_mean_absolute_error: 0.3647\n",
      "Epoch 12/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5111 - mean_absolute_error: 0.5111 - val_loss: 0.3606 - val_mean_absolute_error: 0.3606\n",
      "Epoch 13/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5010 - mean_absolute_error: 0.5010 - val_loss: 0.3541 - val_mean_absolute_error: 0.3541\n",
      "Epoch 14/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4927 - mean_absolute_error: 0.4927 - val_loss: 0.3673 - val_mean_absolute_error: 0.3673\n",
      "Epoch 15/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4865 - mean_absolute_error: 0.4865 - val_loss: 0.3682 - val_mean_absolute_error: 0.3682\n",
      "Epoch 16/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4784 - mean_absolute_error: 0.4784 - val_loss: 0.3784 - val_mean_absolute_error: 0.3784\n",
      "Epoch 17/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4778 - mean_absolute_error: 0.4778 - val_loss: 0.3628 - val_mean_absolute_error: 0.3628\n",
      "Epoch 18/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4729 - mean_absolute_error: 0.4729 - val_loss: 0.3483 - val_mean_absolute_error: 0.3483\n",
      "Epoch 19/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4622 - mean_absolute_error: 0.4622 - val_loss: 0.3429 - val_mean_absolute_error: 0.3429\n",
      "Epoch 20/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4594 - mean_absolute_error: 0.4594 - val_loss: 0.3415 - val_mean_absolute_error: 0.3415\n",
      "Epoch 21/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4535 - mean_absolute_error: 0.4535 - val_loss: 0.3382 - val_mean_absolute_error: 0.3382\n",
      "Epoch 22/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4545 - mean_absolute_error: 0.4545 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299\n",
      "Epoch 23/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4474 - mean_absolute_error: 0.4474 - val_loss: 0.3320 - val_mean_absolute_error: 0.3320\n",
      "Epoch 24/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4445 - mean_absolute_error: 0.4445 - val_loss: 0.3500 - val_mean_absolute_error: 0.3500\n",
      "Epoch 25/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4442 - mean_absolute_error: 0.4442 - val_loss: 0.3325 - val_mean_absolute_error: 0.3325\n",
      "Epoch 26/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4363 - mean_absolute_error: 0.4363 - val_loss: 0.3342 - val_mean_absolute_error: 0.3342\n",
      "Epoch 27/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4366 - mean_absolute_error: 0.4366 - val_loss: 0.3381 - val_mean_absolute_error: 0.3381\n",
      "Epoch 28/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4330 - mean_absolute_error: 0.4330 - val_loss: 0.3454 - val_mean_absolute_error: 0.3454\n",
      "Epoch 29/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4262 - mean_absolute_error: 0.4262 - val_loss: 0.3239 - val_mean_absolute_error: 0.3239\n",
      "Epoch 30/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4279 - mean_absolute_error: 0.4279 - val_loss: 0.3348 - val_mean_absolute_error: 0.3348\n",
      "Epoch 31/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4211 - mean_absolute_error: 0.4211 - val_loss: 0.3350 - val_mean_absolute_error: 0.3350\n",
      "Epoch 32/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4153 - mean_absolute_error: 0.4153 - val_loss: 0.3373 - val_mean_absolute_error: 0.3373\n",
      "Epoch 33/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4223 - mean_absolute_error: 0.4223 - val_loss: 0.3544 - val_mean_absolute_error: 0.3544\n",
      "Epoch 34/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4196 - mean_absolute_error: 0.4196 - val_loss: 0.3600 - val_mean_absolute_error: 0.3600\n",
      "Epoch 35/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4191 - mean_absolute_error: 0.4191 - val_loss: 0.3281 - val_mean_absolute_error: 0.3281\n",
      "Epoch 36/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4137 - mean_absolute_error: 0.4137 - val_loss: 0.3298 - val_mean_absolute_error: 0.3298\n",
      "Epoch 37/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4154 - mean_absolute_error: 0.4154 - val_loss: 0.3255 - val_mean_absolute_error: 0.3255\n",
      "Epoch 38/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4084 - mean_absolute_error: 0.4084 - val_loss: 0.3547 - val_mean_absolute_error: 0.3547\n",
      "Epoch 39/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4123 - mean_absolute_error: 0.4123 - val_loss: 0.3363 - val_mean_absolute_error: 0.3363\n",
      "Epoch 40/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4045 - mean_absolute_error: 0.4045 - val_loss: 0.3362 - val_mean_absolute_error: 0.3362\n",
      "Epoch 41/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4056 - mean_absolute_error: 0.4056 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260\n",
      "Epoch 42/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4031 - mean_absolute_error: 0.4031 - val_loss: 0.3327 - val_mean_absolute_error: 0.3327\n",
      "Epoch 43/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4001 - mean_absolute_error: 0.4001 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303\n",
      "Epoch 44/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3968 - mean_absolute_error: 0.3968 - val_loss: 0.3324 - val_mean_absolute_error: 0.3324\n",
      "Epoch 45/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4007 - mean_absolute_error: 0.4007 - val_loss: 0.3369 - val_mean_absolute_error: 0.3369\n",
      "Epoch 46/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3960 - mean_absolute_error: 0.3960 - val_loss: 0.3193 - val_mean_absolute_error: 0.3193\n",
      "Epoch 47/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3943 - mean_absolute_error: 0.3943 - val_loss: 0.3165 - val_mean_absolute_error: 0.3165\n",
      "Epoch 48/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3908 - mean_absolute_error: 0.3908 - val_loss: 0.3185 - val_mean_absolute_error: 0.3185\n",
      "Epoch 49/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3906 - mean_absolute_error: 0.3906 - val_loss: 0.3337 - val_mean_absolute_error: 0.3337\n",
      "Epoch 50/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3895 - mean_absolute_error: 0.3895 - val_loss: 0.3249 - val_mean_absolute_error: 0.3249\n",
      "Epoch 51/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3884 - mean_absolute_error: 0.3884 - val_loss: 0.3162 - val_mean_absolute_error: 0.3162\n",
      "Epoch 52/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3835 - mean_absolute_error: 0.3835 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238\n",
      "Epoch 53/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3890 - mean_absolute_error: 0.3890 - val_loss: 0.3129 - val_mean_absolute_error: 0.3129\n",
      "Epoch 54/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3870 - mean_absolute_error: 0.3870 - val_loss: 0.3236 - val_mean_absolute_error: 0.3236\n",
      "Epoch 55/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3815 - mean_absolute_error: 0.3815 - val_loss: 0.3113 - val_mean_absolute_error: 0.3113\n",
      "Epoch 56/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3791 - mean_absolute_error: 0.3791 - val_loss: 0.3113 - val_mean_absolute_error: 0.3113\n",
      "Epoch 57/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3821 - mean_absolute_error: 0.3821 - val_loss: 0.3157 - val_mean_absolute_error: 0.3157\n",
      "Epoch 58/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3802 - mean_absolute_error: 0.3802 - val_loss: 0.3474 - val_mean_absolute_error: 0.3474\n",
      "Epoch 59/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3803 - mean_absolute_error: 0.3803 - val_loss: 0.3088 - val_mean_absolute_error: 0.3088\n",
      "Epoch 60/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3783 - mean_absolute_error: 0.3783 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343\n",
      "Epoch 61/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3775 - mean_absolute_error: 0.3775 - val_loss: 0.3221 - val_mean_absolute_error: 0.3221\n",
      "Epoch 62/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3727 - mean_absolute_error: 0.3727 - val_loss: 0.3127 - val_mean_absolute_error: 0.3127\n",
      "Epoch 63/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3781 - mean_absolute_error: 0.3781 - val_loss: 0.3087 - val_mean_absolute_error: 0.3087\n",
      "Epoch 64/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3770 - mean_absolute_error: 0.3770 - val_loss: 0.3124 - val_mean_absolute_error: 0.3124\n",
      "Epoch 65/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3735 - mean_absolute_error: 0.3735 - val_loss: 0.3108 - val_mean_absolute_error: 0.3108\n",
      "Epoch 66/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3750 - mean_absolute_error: 0.3750 - val_loss: 0.3200 - val_mean_absolute_error: 0.3200\n",
      "Epoch 67/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3715 - mean_absolute_error: 0.3715 - val_loss: 0.3263 - val_mean_absolute_error: 0.3263\n",
      "Epoch 68/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3735 - mean_absolute_error: 0.3735 - val_loss: 0.3110 - val_mean_absolute_error: 0.3110\n",
      "Epoch 69/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3686 - mean_absolute_error: 0.3686 - val_loss: 0.3137 - val_mean_absolute_error: 0.3137\n",
      "Epoch 70/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3679 - mean_absolute_error: 0.3679 - val_loss: 0.3092 - val_mean_absolute_error: 0.3092\n",
      "Epoch 71/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3650 - mean_absolute_error: 0.3650 - val_loss: 0.3162 - val_mean_absolute_error: 0.3162\n",
      "Epoch 72/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3670 - mean_absolute_error: 0.3670 - val_loss: 0.3125 - val_mean_absolute_error: 0.3125\n",
      "Epoch 73/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3690 - mean_absolute_error: 0.3690 - val_loss: 0.3171 - val_mean_absolute_error: 0.3171\n",
      "Epoch 74/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3640 - mean_absolute_error: 0.3640 - val_loss: 0.3146 - val_mean_absolute_error: 0.3146\n",
      "Epoch 75/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3682 - mean_absolute_error: 0.3682 - val_loss: 0.3122 - val_mean_absolute_error: 0.3122\n",
      "Epoch 76/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3653 - mean_absolute_error: 0.3653 - val_loss: 0.3081 - val_mean_absolute_error: 0.3081\n",
      "Epoch 77/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3653 - mean_absolute_error: 0.3653 - val_loss: 0.3125 - val_mean_absolute_error: 0.3125\n",
      "Epoch 78/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3641 - mean_absolute_error: 0.3641 - val_loss: 0.3034 - val_mean_absolute_error: 0.3034\n",
      "Epoch 79/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3628 - mean_absolute_error: 0.3628 - val_loss: 0.3101 - val_mean_absolute_error: 0.3101\n",
      "Epoch 80/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3642 - mean_absolute_error: 0.3642 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 81/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3607 - mean_absolute_error: 0.3607 - val_loss: 0.3107 - val_mean_absolute_error: 0.3107\n",
      "Epoch 82/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3597 - mean_absolute_error: 0.3597 - val_loss: 0.3116 - val_mean_absolute_error: 0.3116\n",
      "Epoch 83/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3621 - mean_absolute_error: 0.3621 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 84/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3562 - mean_absolute_error: 0.3562 - val_loss: 0.3056 - val_mean_absolute_error: 0.3056\n",
      "Epoch 85/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3576 - mean_absolute_error: 0.3576 - val_loss: 0.3040 - val_mean_absolute_error: 0.3040\n",
      "Epoch 86/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3552 - mean_absolute_error: 0.3552 - val_loss: 0.3065 - val_mean_absolute_error: 0.3065\n",
      "Epoch 87/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3570 - mean_absolute_error: 0.3570 - val_loss: 0.3225 - val_mean_absolute_error: 0.3225\n",
      "Epoch 88/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3573 - mean_absolute_error: 0.3573 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 89/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3524 - mean_absolute_error: 0.3524 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 90/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3532 - mean_absolute_error: 0.3532 - val_loss: 0.3104 - val_mean_absolute_error: 0.3104\n",
      "Epoch 91/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3530 - mean_absolute_error: 0.3530 - val_loss: 0.3078 - val_mean_absolute_error: 0.3078\n",
      "Epoch 92/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3527 - mean_absolute_error: 0.3527 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 93/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3492 - mean_absolute_error: 0.3492 - val_loss: 0.3117 - val_mean_absolute_error: 0.3117\n",
      "Epoch 94/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3490 - mean_absolute_error: 0.3490 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 95/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3509 - mean_absolute_error: 0.3509 - val_loss: 0.3086 - val_mean_absolute_error: 0.3086\n",
      "Epoch 96/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3470 - mean_absolute_error: 0.3470 - val_loss: 0.3024 - val_mean_absolute_error: 0.3024\n",
      "Epoch 97/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3496 - mean_absolute_error: 0.3496 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 98/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3446 - mean_absolute_error: 0.3446 - val_loss: 0.3130 - val_mean_absolute_error: 0.3130\n",
      "Epoch 99/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3477 - mean_absolute_error: 0.3477 - val_loss: 0.3101 - val_mean_absolute_error: 0.3101\n",
      "Epoch 100/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3465 - mean_absolute_error: 0.3465 - val_loss: 0.3046 - val_mean_absolute_error: 0.3046\n",
      "Epoch 101/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3443 - mean_absolute_error: 0.3443 - val_loss: 0.3049 - val_mean_absolute_error: 0.3049\n",
      "Epoch 102/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3481 - mean_absolute_error: 0.3481 - val_loss: 0.3169 - val_mean_absolute_error: 0.3169\n",
      "Epoch 103/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3453 - mean_absolute_error: 0.3453 - val_loss: 0.3075 - val_mean_absolute_error: 0.3075\n",
      "Epoch 104/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3448 - mean_absolute_error: 0.3448 - val_loss: 0.3062 - val_mean_absolute_error: 0.3062\n",
      "Epoch 105/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3441 - mean_absolute_error: 0.3441 - val_loss: 0.3043 - val_mean_absolute_error: 0.3043\n",
      "Epoch 106/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3417 - mean_absolute_error: 0.3417 - val_loss: 0.3086 - val_mean_absolute_error: 0.3086\n",
      "Epoch 107/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3444 - mean_absolute_error: 0.3444 - val_loss: 0.3052 - val_mean_absolute_error: 0.3052\n",
      "Epoch 108/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3419 - mean_absolute_error: 0.3419 - val_loss: 0.3183 - val_mean_absolute_error: 0.3183\n",
      "Epoch 109/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3412 - mean_absolute_error: 0.3412 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "Epoch 110/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3371 - mean_absolute_error: 0.3371 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 111/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3344 - mean_absolute_error: 0.3344 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 112/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3365 - mean_absolute_error: 0.3365 - val_loss: 0.3148 - val_mean_absolute_error: 0.3148\n",
      "Epoch 113/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3413 - mean_absolute_error: 0.3413 - val_loss: 0.3031 - val_mean_absolute_error: 0.3031\n",
      "Epoch 114/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3393 - mean_absolute_error: 0.3393 - val_loss: 0.3039 - val_mean_absolute_error: 0.3039\n",
      "Epoch 115/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3398 - mean_absolute_error: 0.3398 - val_loss: 0.3072 - val_mean_absolute_error: 0.3072\n",
      "Epoch 116/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3351 - mean_absolute_error: 0.3351 - val_loss: 0.3057 - val_mean_absolute_error: 0.3057\n",
      "Epoch 117/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3375 - mean_absolute_error: 0.3375 - val_loss: 0.3051 - val_mean_absolute_error: 0.3051\n",
      "Epoch 118/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3343 - mean_absolute_error: 0.3343 - val_loss: 0.3092 - val_mean_absolute_error: 0.3092\n",
      "Epoch 119/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3345 - mean_absolute_error: 0.3345 - val_loss: 0.3086 - val_mean_absolute_error: 0.3086\n",
      "Epoch 120/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3363 - mean_absolute_error: 0.3363 - val_loss: 0.3037 - val_mean_absolute_error: 0.3037\n",
      "Epoch 121/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3311 - mean_absolute_error: 0.3311 - val_loss: 0.3014 - val_mean_absolute_error: 0.3014\n",
      "Epoch 122/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3309 - mean_absolute_error: 0.3309 - val_loss: 0.3012 - val_mean_absolute_error: 0.3012\n",
      "Epoch 123/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3332 - mean_absolute_error: 0.3332 - val_loss: 0.3038 - val_mean_absolute_error: 0.3038\n",
      "Epoch 124/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3332 - mean_absolute_error: 0.3332 - val_loss: 0.3075 - val_mean_absolute_error: 0.3075\n",
      "Epoch 125/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3334 - mean_absolute_error: 0.3334 - val_loss: 0.3045 - val_mean_absolute_error: 0.3045\n",
      "Epoch 126/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3306 - mean_absolute_error: 0.3306 - val_loss: 0.3068 - val_mean_absolute_error: 0.3068\n",
      "Epoch 127/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3296 - mean_absolute_error: 0.3296 - val_loss: 0.3054 - val_mean_absolute_error: 0.3054\n",
      "Epoch 128/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3308 - mean_absolute_error: 0.3308 - val_loss: 0.3017 - val_mean_absolute_error: 0.3017\n",
      "Epoch 129/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3300 - mean_absolute_error: 0.3300 - val_loss: 0.3073 - val_mean_absolute_error: 0.3073\n",
      "Epoch 130/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3285 - mean_absolute_error: 0.3285 - val_loss: 0.3055 - val_mean_absolute_error: 0.3055\n",
      "Epoch 131/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3270 - mean_absolute_error: 0.3270 - val_loss: 0.3066 - val_mean_absolute_error: 0.3066\n",
      "Epoch 132/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3279 - mean_absolute_error: 0.3279 - val_loss: 0.3014 - val_mean_absolute_error: 0.3014\n",
      "Epoch 133/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3290 - mean_absolute_error: 0.3290 - val_loss: 0.3004 - val_mean_absolute_error: 0.3004\n",
      "Epoch 134/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3252 - mean_absolute_error: 0.3252 - val_loss: 0.3044 - val_mean_absolute_error: 0.3044\n",
      "Epoch 135/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3261 - mean_absolute_error: 0.3261 - val_loss: 0.3019 - val_mean_absolute_error: 0.3019\n",
      "Epoch 136/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3247 - mean_absolute_error: 0.3247 - val_loss: 0.3078 - val_mean_absolute_error: 0.3078\n",
      "Epoch 137/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3243 - mean_absolute_error: 0.3243 - val_loss: 0.3020 - val_mean_absolute_error: 0.3020\n",
      "Epoch 138/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3216 - mean_absolute_error: 0.3216 - val_loss: 0.3042 - val_mean_absolute_error: 0.3042\n",
      "Epoch 139/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3228 - mean_absolute_error: 0.3228 - val_loss: 0.3035 - val_mean_absolute_error: 0.3035\n",
      "Epoch 140/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3227 - mean_absolute_error: 0.3227 - val_loss: 0.3113 - val_mean_absolute_error: 0.3113\n",
      "Epoch 141/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3277 - mean_absolute_error: 0.3277 - val_loss: 0.3018 - val_mean_absolute_error: 0.3018\n",
      "Epoch 142/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3240 - mean_absolute_error: 0.3240 - val_loss: 0.3016 - val_mean_absolute_error: 0.3016\n",
      "Epoch 143/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3188 - mean_absolute_error: 0.3188 - val_loss: 0.3154 - val_mean_absolute_error: 0.3154\n",
      "Epoch 144/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3196 - mean_absolute_error: 0.3196 - val_loss: 0.3058 - val_mean_absolute_error: 0.3058\n",
      "Epoch 145/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3206 - mean_absolute_error: 0.3206 - val_loss: 0.3140 - val_mean_absolute_error: 0.3140\n",
      "Epoch 146/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3204 - mean_absolute_error: 0.3204 - val_loss: 0.3027 - val_mean_absolute_error: 0.3027\n",
      "Epoch 147/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3205 - mean_absolute_error: 0.3205 - val_loss: 0.3021 - val_mean_absolute_error: 0.3021\n",
      "Epoch 148/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3185 - mean_absolute_error: 0.3185 - val_loss: 0.3047 - val_mean_absolute_error: 0.3047\n",
      "Epoch 149/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3168 - mean_absolute_error: 0.3168 - val_loss: 0.3016 - val_mean_absolute_error: 0.3016\n",
      "Epoch 150/150\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3186 - mean_absolute_error: 0.3186 - val_loss: 0.3041 - val_mean_absolute_error: 0.3041\n",
      "         loss  mean_absolute_error  val_loss  val_mean_absolute_error  epoch\n",
      "145  0.320406             0.320406  0.302700                 0.302700    145\n",
      "146  0.320515             0.320515  0.302115                 0.302115    146\n",
      "147  0.318464             0.318464  0.304739                 0.304739    147\n",
      "148  0.316806             0.316806  0.301616                 0.301616    148\n",
      "149  0.318572             0.318572  0.304146                 0.304146    149\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE en log(price) - test: 0.2925\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "MAE aproximado en price (escala original): 164.79\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Entreno un primer modelo base con la arquitectura por defecto\n",
    "# para tener una referencia de desempeño y revisar que el entrenamiento sea estable.\n",
    "\n",
    "baseline_model = build_mlp_model(\n",
    "    n_hidden_layers=2,\n",
    "    units_per_layer=64,\n",
    "    dropout_rate=0.10,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# EarlyStopping para no quedarme entrenando de más una arquitectura que ya dejó de mejorar\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrenamiento del modelo base\n",
    "history_base = baseline_model.fit(\n",
    "    X_train_nn,\n",
    "    y_train_nn,\n",
    "    epochs=150,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Convierto el historial a DataFrame para poder graficar más fácil\n",
    "hist_base = pd.DataFrame(history_base.history)\n",
    "hist_base[\"epoch\"] = history_base.epoch\n",
    "\n",
    "print(hist_base.tail())\n",
    "\n",
    "# Curva de pérdida (MAE) en entrenamiento y validación\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(hist_base[\"loss\"], label=\"loss_train\")\n",
    "plt.plot(hist_base[\"val_loss\"], label=\"loss_val\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"MAE en log(price)\")\n",
    "plt.title(\"Evolución de la pérdida - Modelo base MLP\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluación en el conjunto de prueba en escala log(price)\n",
    "test_loss_log, test_mae_log = baseline_model.evaluate(X_test_nn, y_test_nn, verbose=0)\n",
    "print(f\"MAE en log(price) - test: {test_mae_log:.4f}\")\n",
    "\n",
    "# Paso el error a escala de precio original para tener una idea más intuitiva (en dólares)\n",
    "y_pred_test_log = baseline_model.predict(X_test_nn).flatten()\n",
    "y_pred_test_price = np.exp(y_pred_test_log)\n",
    "y_test_price = np.exp(y_test_nn)\n",
    "\n",
    "mae_price = np.mean(np.abs(y_pred_test_price - y_test_price))\n",
    "print(f\"MAE aproximado en price (escala original): {mae_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a566cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de configuraciones que voy a probar: 16\n",
      "\n",
      "====================================\n",
      "Modelo 1\n",
      "Capas: 1, unidades: 32, dropout: 0.0, lr: 0.001\n",
      "Mejor val MAE (log): 0.3567\n",
      "MAE test (log): 0.3263\n",
      "MAE aproximado en price: 433.44\n",
      "\n",
      "====================================\n",
      "Modelo 2\n",
      "Capas: 1, unidades: 64, dropout: 0.1, lr: 0.001\n",
      "Mejor val MAE (log): 0.3371\n",
      "MAE test (log): 0.3099\n",
      "MAE aproximado en price: 179.35\n",
      "\n",
      "====================================\n",
      "Modelo 3\n",
      "Capas: 1, unidades: 96, dropout: 0.2, lr: 0.0005\n",
      "Mejor val MAE (log): 0.3270\n",
      "MAE test (log): 0.3090\n",
      "MAE aproximado en price: 200.08\n",
      "\n",
      "====================================\n",
      "Modelo 4\n",
      "Capas: 2, unidades: 48, dropout: 0.1, lr: 0.001\n",
      "Mejor val MAE (log): 0.3202\n",
      "MAE test (log): 0.3082\n",
      "MAE aproximado en price: 183.65\n",
      "\n",
      "====================================\n",
      "Modelo 5\n",
      "Capas: 2, unidades: 64, dropout: 0.2, lr: 0.001\n",
      "Mejor val MAE (log): 0.3189\n",
      "MAE test (log): 0.3063\n",
      "MAE aproximado en price: 175.24\n",
      "\n",
      "====================================\n",
      "Modelo 6\n",
      "Capas: 2, unidades: 96, dropout: 0.1, lr: 0.0005\n",
      "Mejor val MAE (log): 0.3123\n",
      "MAE test (log): 0.3039\n",
      "MAE aproximado en price: 169.68\n",
      "\n",
      "====================================\n",
      "Modelo 7\n",
      "Capas: 3, unidades: 64, dropout: 0.1, lr: 0.001\n",
      "Mejor val MAE (log): 0.3234\n",
      "MAE test (log): 0.3136\n",
      "MAE aproximado en price: 185.39\n",
      "\n",
      "====================================\n",
      "Modelo 8\n",
      "Capas: 3, unidades: 96, dropout: 0.2, lr: 0.001\n",
      "Mejor val MAE (log): 0.3427\n",
      "MAE test (log): 0.3342\n",
      "MAE aproximado en price: 175.11\n",
      "\n",
      "====================================\n",
      "Modelo 9\n",
      "Capas: 3, unidades: 128, dropout: 0.2, lr: 0.0005\n",
      "Mejor val MAE (log): 0.3721\n",
      "MAE test (log): 0.3674\n",
      "MAE aproximado en price: 201.28\n",
      "\n",
      "====================================\n",
      "Modelo 10\n",
      "Capas: 4, unidades: 64, dropout: 0.15, lr: 0.001\n",
      "Mejor val MAE (log): 0.3407\n",
      "MAE test (log): 0.3319\n",
      "MAE aproximado en price: 190.28\n",
      "\n",
      "====================================\n",
      "Modelo 11\n",
      "Capas: 4, unidades: 96, dropout: 0.25, lr: 0.001\n",
      "Mejor val MAE (log): 0.3536\n",
      "MAE test (log): 0.3444\n",
      "MAE aproximado en price: 193.63\n",
      "\n",
      "====================================\n",
      "Modelo 12\n",
      "Capas: 4, unidades: 128, dropout: 0.15, lr: 0.0005\n",
      "Mejor val MAE (log): 0.3779\n",
      "MAE test (log): 0.3696\n",
      "MAE aproximado en price: 186.02\n",
      "\n",
      "====================================\n",
      "Modelo 13\n",
      "Capas: 5, unidades: 64, dropout: 0.2, lr: 0.001\n",
      "Mejor val MAE (log): 0.3629\n",
      "MAE test (log): 0.3497\n",
      "MAE aproximado en price: 189.52\n",
      "\n",
      "====================================\n",
      "Modelo 14\n",
      "Capas: 5, unidades: 96, dropout: 0.3, lr: 0.001\n",
      "Mejor val MAE (log): 0.3638\n",
      "MAE test (log): 0.3487\n",
      "MAE aproximado en price: 208.25\n",
      "\n",
      "====================================\n",
      "Modelo 15\n",
      "Capas: 5, unidades: 128, dropout: 0.25, lr: 0.0005\n",
      "Mejor val MAE (log): 0.3480\n",
      "MAE test (log): 0.3346\n",
      "MAE aproximado en price: 193.39\n",
      "\n",
      "====================================\n",
      "Modelo 16\n",
      "Capas: 3, unidades: 160, dropout: 0.2, lr: 0.0005\n",
      "Mejor val MAE (log): 0.4331\n",
      "MAE test (log): 0.4239\n",
      "MAE aproximado en price: 197.78\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lista donde voy a ir guardando todo lo que salga de cada modelo\n",
    "hp_results = []\n",
    "\n",
    "# Defino varias configuraciones de hiperparámetros\n",
    "# Capas, unidades variadas, dropout y learning rate distintos\n",
    "config_1  = {\"n_layers\": 1, \"units\": 32,  \"dropout\": 0.00, \"lr\": 0.001}\n",
    "config_2  = {\"n_layers\": 1, \"units\": 64,  \"dropout\": 0.10, \"lr\": 0.001}\n",
    "config_3  = {\"n_layers\": 1, \"units\": 96,  \"dropout\": 0.20, \"lr\": 0.0005}\n",
    "\n",
    "config_4  = {\"n_layers\": 2, \"units\": 48,  \"dropout\": 0.10, \"lr\": 0.001}\n",
    "config_5  = {\"n_layers\": 2, \"units\": 64,  \"dropout\": 0.20, \"lr\": 0.001}\n",
    "config_6  = {\"n_layers\": 2, \"units\": 96,  \"dropout\": 0.10, \"lr\": 0.0005}\n",
    "\n",
    "config_7  = {\"n_layers\": 3, \"units\": 64,  \"dropout\": 0.10, \"lr\": 0.001}\n",
    "config_8  = {\"n_layers\": 3, \"units\": 96,  \"dropout\": 0.20, \"lr\": 0.001}\n",
    "config_9  = {\"n_layers\": 3, \"units\": 128, \"dropout\": 0.20, \"lr\": 0.0005}\n",
    "\n",
    "config_10 = {\"n_layers\": 4, \"units\": 64,  \"dropout\": 0.15, \"lr\": 0.001}\n",
    "config_11 = {\"n_layers\": 4, \"units\": 96,  \"dropout\": 0.25, \"lr\": 0.001}\n",
    "config_12 = {\"n_layers\": 4, \"units\": 128, \"dropout\": 0.15, \"lr\": 0.0005}\n",
    "\n",
    "config_13 = {\"n_layers\": 5, \"units\": 64,  \"dropout\": 0.20, \"lr\": 0.001}\n",
    "config_14 = {\"n_layers\": 5, \"units\": 96,  \"dropout\": 0.30, \"lr\": 0.001}\n",
    "config_15 = {\"n_layers\": 5, \"units\": 128, \"dropout\": 0.25, \"lr\": 0.0005}\n",
    "config_16 = {\"n_layers\": 3, \"units\": 160, \"dropout\": 0.20, \"lr\": 0.0005}\n",
    "\n",
    "config_list = [\n",
    "    config_1, config_2, config_3,\n",
    "    config_4, config_5, config_6,\n",
    "    config_7, config_8, config_9,\n",
    "    config_10, config_11, config_12,\n",
    "    config_13, config_14, config_15,\n",
    "    config_16\n",
    "]\n",
    "\n",
    "print(\"Número de configuraciones que voy a probar:\", len(config_list))\n",
    "\n",
    "for i, cfg in enumerate(config_list, start=1):\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"Modelo {i}\")\n",
    "    print(f\"Capas: {cfg['n_layers']}, unidades: {cfg['units']}, dropout: {cfg['dropout']}, lr: {cfg['lr']}\")\n",
    "    \n",
    "    # Construyo el modelo con esta configuración\n",
    "    model_tmp = build_mlp_model(\n",
    "        n_hidden_layers=cfg[\"n_layers\"],\n",
    "        units_per_layer=cfg[\"units\"],\n",
    "        dropout_rate=cfg[\"dropout\"],\n",
    "        learning_rate=cfg[\"lr\"]\n",
    "    )\n",
    "    \n",
    "    # Early stopping para evitar sobreentrenar modelos que dejan de mejorar\n",
    "    early_stop_tmp = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history_tmp = model_tmp.fit(\n",
    "        X_train_nn,\n",
    "        y_train_nn,\n",
    "        epochs=120,\n",
    "        batch_size=256,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop_tmp],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Mejor MAE de validación (en log(price)) que alcanzó este modelo\n",
    "    best_val_mae_log = float(np.min(history_tmp.history[\"val_loss\"]))\n",
    "    \n",
    "    # Evaluación en el conjunto de prueba en log(price)\n",
    "    test_loss_log, test_mae_log = model_tmp.evaluate(X_test_nn, y_test_nn, verbose=0)\n",
    "    \n",
    "    # Paso a escala original para tener una idea del error en dólares\n",
    "    y_pred_test_log_tmp = model_tmp.predict(X_test_nn, verbose=0).flatten()\n",
    "    y_pred_test_price_tmp = np.exp(y_pred_test_log_tmp)\n",
    "    y_test_price_tmp = np.exp(y_test_nn)\n",
    "    mae_price_tmp = float(np.mean(np.abs(y_pred_test_price_tmp - y_test_price_tmp)))\n",
    "    \n",
    "    # Número de épocas reales entrenadas\n",
    "    epochs_trained = len(history_tmp.history[\"loss\"])\n",
    "    \n",
    "    # Guardo resultados de este modelo\n",
    "    hp_results.append({\n",
    "        \"model_id\": i,\n",
    "        \"n_layers\": cfg[\"n_layers\"],\n",
    "        \"units\": cfg[\"units\"],\n",
    "        \"dropout\": cfg[\"dropout\"],\n",
    "        \"learning_rate\": cfg[\"lr\"],\n",
    "        \"best_val_mae_log\": best_val_mae_log,\n",
    "        \"test_mae_log\": float(test_mae_log),\n",
    "        \"mae_price\": mae_price_tmp,\n",
    "        \"epochs_trained\": epochs_trained,\n",
    "        \"history\": history_tmp,\n",
    "        \"model_obj\": model_tmp\n",
    "    })\n",
    "    \n",
    "    print(f\"Mejor val MAE (log): {best_val_mae_log:.4f}\")\n",
    "    print(f\"MAE test (log): {test_mae_log:.4f}\")\n",
    "    print(f\"MAE aproximado en price: {mae_price_tmp:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3339e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451098bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556b772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
