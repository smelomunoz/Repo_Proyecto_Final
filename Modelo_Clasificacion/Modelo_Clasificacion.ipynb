{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a35b017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  accommodates  price_per_guest borough_seg    room_type_seg\n",
      "0   66.0             1        66.000000      Queens     Private room\n",
      "1   76.0             1        76.000000   Manhattan     Private room\n",
      "2   97.0             6        16.166667      Queens  Entire home/apt\n",
      "3   60.0             1        60.000000    Brooklyn     Private room\n",
      "4  425.0             6        70.833333    Brooklyn  Entire home/apt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargo la base limpia con la que hemos venido trabajando\n",
    "df = pd.read_csv(\"df_cleaned.csv\")\n",
    "\n",
    "# Aseguro tipos básicos que voy a usar\n",
    "df[\"price\"] = df[\"price\"].astype(float)\n",
    "df[\"accommodates\"] = df[\"accommodates\"].astype(int)\n",
    "\n",
    "# Precio por huésped como indicador de valor relativo\n",
    "df[\"price_per_guest\"] = df[\"price\"] / df[\"accommodates\"]\n",
    "\n",
    "# Reconstruyo el borough a partir de las dummies de neighbourhood_group_cleansed\n",
    "borough_cols = [\n",
    "    \"neighbourhood_group_cleansed:Bronx\",\n",
    "    \"neighbourhood_group_cleansed:Brooklyn\",\n",
    "    \"neighbourhood_group_cleansed:Manhattan\",\n",
    "    \"neighbourhood_group_cleansed:Queens\",\n",
    "    \"neighbourhood_group_cleansed:Staten Island\"\n",
    "]\n",
    "\n",
    "df[\"borough_seg\"] = (\n",
    "    df[borough_cols]\n",
    "      .idxmax(axis=1)          # columna que tiene el 1\n",
    "      .str.split(\":\", n=1)\n",
    "      .str[1]                  # me quedo con Bronx, Brooklyn, etc.\n",
    ")\n",
    "\n",
    "# Reconstruyo el tipo de habitación a partir de las dummies de room_type\n",
    "room_cols = [\n",
    "    \"room_type:Entire home/apt\",\n",
    "    \"room_type:Hotel room\",\n",
    "    \"room_type:Private room\",\n",
    "    \"room_type:Shared room\"\n",
    "]\n",
    "\n",
    "df[\"room_type_seg\"] = (\n",
    "    df[room_cols]\n",
    "      .idxmax(axis=1)\n",
    "      .str.split(\":\", n=1)\n",
    "      .str[1]\n",
    ")\n",
    "\n",
    "# Reviso rápido que las nuevas columnas tengan sentido\n",
    "print(df[[\"price\", \"accommodates\", \"price_per_guest\", \"borough_seg\", \"room_type_seg\"]].head())\n",
    "\n",
    "# Guardo esta base intermedia para el modelo 3\n",
    "df.to_csv(\"df_modelo3_segmentos_base.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aad41bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de la etiqueta recommended:\n",
      "recommended\n",
      "0    15283\n",
      "1     5544\n",
      "Name: count, dtype: int64\n",
      "recommended\n",
      "0    0.734\n",
      "1    0.266\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargo la base intermedia generada en el commit 1\n",
    "df = pd.read_csv(\"df_modelo3_segmentos_base.csv\")\n",
    "\n",
    "# Defino el segmento comparable: mismo borough + mismo tipo de habitación\n",
    "segment_cols = [\"borough_seg\", \"room_type_seg\"]\n",
    "\n",
    "# Para cada segmento calculo:\n",
    "# - percentil 25 y 75 de price_per_guest (rango razonable de precio por huésped)\n",
    "# - mediana de amenities_count (mínimo razonable de amenidades)\n",
    "segment_stats = (\n",
    "    df.groupby(segment_cols)\n",
    "      .agg(\n",
    "          p25_ppg=(\"price_per_guest\", lambda x: np.percentile(x, 25)),\n",
    "          p75_ppg=(\"price_per_guest\", lambda x: np.percentile(x, 75)),\n",
    "          med_amenities=(\"amenities_count\", \"median\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Uno estas estadísticas al dataframe principal\n",
    "df = df.merge(segment_stats, on=segment_cols, how=\"left\")\n",
    "\n",
    "# Regla de recomendación:\n",
    "# - price_per_guest entre p25 y p75 del segmento\n",
    "# - amenities_count >= med_amenities del segmento\n",
    "cond_precio = (df[\"price_per_guest\"] >= df[\"p25_ppg\"]) & (df[\"price_per_guest\"] <= df[\"p75_ppg\"])\n",
    "cond_amenities = df[\"amenities_count\"] >= df[\"med_amenities\"]\n",
    "\n",
    "df[\"recommended\"] = np.where(cond_precio & cond_amenities, 1, 0)\n",
    "\n",
    "# Reviso que la etiqueta no quede extremadamente desbalanceada\n",
    "print(\"Distribución de la etiqueta recommended:\")\n",
    "print(df[\"recommended\"].value_counts(dropna=False))\n",
    "print(df[\"recommended\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Guardo la base final para el modelo de clasificación\n",
    "df.to_csv(\"df_modelo3_clasificacion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea19855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de la clase objetivo:\n",
      "recommended\n",
      "0    15283\n",
      "1     5544\n",
      "Name: count, dtype: int64\n",
      "recommended\n",
      "0    0.734\n",
      "1    0.266\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Número de variables explicativas seleccionadas: 100\n",
      "Tamaños de los conjuntos:\n",
      "X_train: (16661, 100)\n",
      "X_test : (4166, 100)\n",
      "\n",
      "Ejemplo de fila escalada:\n",
      "[-3.9586241  -2.802569    0.12077124  1.4168756  -0.43168676 -0.3549193\n",
      " -0.37398288 -0.54305923 -0.13032001  0.14498988]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargo la base ya con la etiqueta recommended\n",
    "df = pd.read_csv(\"df_modelo3_clasificacion.csv\")\n",
    "\n",
    "# Variable objetivo: recommended (0 = no recomendada, 1 = recomendada)\n",
    "y = df[\"recommended\"].astype(int)\n",
    "\n",
    "print(\"Distribución de la clase objetivo:\")\n",
    "print(y.value_counts(dropna=False))\n",
    "print(y.value_counts(normalize=True).round(3))\n",
    "\n",
    "# Defino qué columnas NO quiero usar como features\n",
    "# (target, textos, columnas de ayuda para construir la etiqueta, etc.)\n",
    "cols_excluir = [\n",
    "    \"recommended\",          # target\n",
    "    \"amenities\",            # lista de amenities en texto\n",
    "    \"bathrooms_text\",       # texto descriptivo del baño\n",
    "    \"calendar_last_scraped\",\n",
    "    \"host_since\",\n",
    "    \"host_response_time\",\n",
    "    \"price_range\",\n",
    "    \"borough_seg\",          # ya se usó para definir la regla de negocio\n",
    "    \"room_type_seg\",        # igual\n",
    "    \"p25_ppg\",\n",
    "    \"p75_ppg\",\n",
    "    \"med_amenities\"\n",
    "]\n",
    "\n",
    "# Me quedo solo con las columnas que sí van a entrar al modelo\n",
    "# (tanto numéricas como dummies que ya vienen en el dataset)\n",
    "cols_features = [c for c in df.columns if c not in cols_excluir]\n",
    "\n",
    "X = df[cols_features].copy()\n",
    "\n",
    "print(\"\\nNúmero de variables explicativas seleccionadas:\", X.shape[1])\n",
    "\n",
    "# Split train / test estratificado para respetar la proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamaños de los conjuntos:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "\n",
    "# Escalado estándar de todas las features (los dummies pasan de 0/1 a valores centrados, lo cual está bien para la red)\n",
    "scaler_clf = StandardScaler()\n",
    "scaler_clf.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler_clf.transform(X_train)\n",
    "X_test_scaled = scaler_clf.transform(X_test)\n",
    "\n",
    "# Paso a float32 por compatibilidad con TensorFlow\n",
    "X_train_scaled = X_train_scaled.astype(\"float32\")\n",
    "X_test_scaled = X_test_scaled.astype(\"float32\")\n",
    "\n",
    "y_train = y_train.values.astype(\"float32\")\n",
    "y_test = y_test.values.astype(\"float32\")\n",
    "\n",
    "print(\"\\nEjemplo de fila escalada:\")\n",
    "print(X_train_scaled[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64046468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\santy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Dimensión de entrada del modelo de clasificación: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,777</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,777\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6838 - loss: 0.5807 - precision: 0.3720 - recall: 0.2819 - val_accuracy: 0.7234 - val_loss: 0.5043 - val_precision: 0.4626 - val_recall: 0.1093\n",
      "Epoch 2/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.4707 - precision: 0.5220 - recall: 0.2049 - val_accuracy: 0.7345 - val_loss: 0.4668 - val_precision: 0.5210 - val_recall: 0.2870\n",
      "Epoch 3/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.4431 - precision: 0.5697 - recall: 0.3415 - val_accuracy: 0.7495 - val_loss: 0.4509 - val_precision: 0.5559 - val_recall: 0.3896\n",
      "Epoch 4/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.4270 - precision: 0.5875 - recall: 0.4052 - val_accuracy: 0.7567 - val_loss: 0.4412 - val_precision: 0.5708 - val_recall: 0.4227\n",
      "Epoch 5/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4144 - precision: 0.5989 - recall: 0.4418 - val_accuracy: 0.7516 - val_loss: 0.4337 - val_precision: 0.5548 - val_recall: 0.4360\n",
      "Epoch 6/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 0.4032 - precision: 0.6068 - recall: 0.4693 - val_accuracy: 0.7522 - val_loss: 0.4275 - val_precision: 0.5529 - val_recall: 0.4614\n",
      "Epoch 7/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.3934 - precision: 0.6104 - recall: 0.5013 - val_accuracy: 0.7558 - val_loss: 0.4225 - val_precision: 0.5596 - val_recall: 0.4768\n",
      "Epoch 8/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.3849 - precision: 0.6139 - recall: 0.5290 - val_accuracy: 0.7579 - val_loss: 0.4185 - val_precision: 0.5629 - val_recall: 0.4890\n",
      "Epoch 9/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.3778 - precision: 0.6194 - recall: 0.5511 - val_accuracy: 0.7606 - val_loss: 0.4150 - val_precision: 0.5672 - val_recall: 0.5033\n",
      "Epoch 10/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.3711 - precision: 0.6209 - recall: 0.5670 - val_accuracy: 0.7603 - val_loss: 0.4115 - val_precision: 0.5656 - val_recall: 0.5088\n",
      "Epoch 11/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.3652 - precision: 0.6258 - recall: 0.5809 - val_accuracy: 0.7627 - val_loss: 0.4082 - val_precision: 0.5689 - val_recall: 0.5243\n",
      "Epoch 12/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.3598 - precision: 0.6277 - recall: 0.5939 - val_accuracy: 0.7669 - val_loss: 0.4054 - val_precision: 0.5758 - val_recall: 0.5408\n",
      "Epoch 13/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.3547 - precision: 0.6336 - recall: 0.6033 - val_accuracy: 0.7687 - val_loss: 0.4030 - val_precision: 0.5797 - val_recall: 0.5419\n",
      "Epoch 14/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.3502 - precision: 0.6392 - recall: 0.6194 - val_accuracy: 0.7714 - val_loss: 0.4005 - val_precision: 0.5826 - val_recall: 0.5607\n",
      "Epoch 15/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.3458 - precision: 0.6415 - recall: 0.6282 - val_accuracy: 0.7735 - val_loss: 0.3982 - val_precision: 0.5861 - val_recall: 0.5673\n",
      "Epoch 16/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.3417 - precision: 0.6441 - recall: 0.6328 - val_accuracy: 0.7759 - val_loss: 0.3964 - val_precision: 0.5894 - val_recall: 0.5784\n",
      "Epoch 17/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.3379 - precision: 0.6466 - recall: 0.6398 - val_accuracy: 0.7774 - val_loss: 0.3950 - val_precision: 0.5913 - val_recall: 0.5861\n",
      "Epoch 18/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8148 - loss: 0.3344 - precision: 0.6517 - recall: 0.6452 - val_accuracy: 0.7789 - val_loss: 0.3936 - val_precision: 0.5938 - val_recall: 0.5905\n",
      "Epoch 19/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.3308 - precision: 0.6584 - recall: 0.6549 - val_accuracy: 0.7798 - val_loss: 0.3926 - val_precision: 0.5947 - val_recall: 0.5960\n",
      "Epoch 20/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.3276 - precision: 0.6582 - recall: 0.6642 - val_accuracy: 0.7828 - val_loss: 0.3915 - val_precision: 0.5998 - val_recall: 0.6038\n",
      "Epoch 21/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.3244 - precision: 0.6642 - recall: 0.6721 - val_accuracy: 0.7852 - val_loss: 0.3906 - val_precision: 0.6035 - val_recall: 0.6115\n",
      "Epoch 22/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.3215 - precision: 0.6691 - recall: 0.6767 - val_accuracy: 0.7867 - val_loss: 0.3895 - val_precision: 0.6054 - val_recall: 0.6181\n",
      "Epoch 23/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.3189 - precision: 0.6720 - recall: 0.6832 - val_accuracy: 0.7876 - val_loss: 0.3890 - val_precision: 0.6069 - val_recall: 0.6203\n",
      "Epoch 24/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8298 - loss: 0.3163 - precision: 0.6758 - recall: 0.6869 - val_accuracy: 0.7885 - val_loss: 0.3888 - val_precision: 0.6091 - val_recall: 0.6192\n",
      "Epoch 25/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3140 - precision: 0.6774 - recall: 0.6891 - val_accuracy: 0.7867 - val_loss: 0.3885 - val_precision: 0.6045 - val_recall: 0.6225\n",
      "Epoch 26/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3117 - precision: 0.6802 - recall: 0.6925 - val_accuracy: 0.7870 - val_loss: 0.3884 - val_precision: 0.6056 - val_recall: 0.6203\n",
      "Epoch 27/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3096 - precision: 0.6819 - recall: 0.6948 - val_accuracy: 0.7897 - val_loss: 0.3892 - val_precision: 0.6113 - val_recall: 0.6214\n",
      "Epoch 28/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.3075 - precision: 0.6853 - recall: 0.7016 - val_accuracy: 0.7918 - val_loss: 0.3881 - val_precision: 0.6147 - val_recall: 0.6269\n",
      "Epoch 29/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.3054 - precision: 0.6875 - recall: 0.7056 - val_accuracy: 0.7912 - val_loss: 0.3909 - val_precision: 0.6124 - val_recall: 0.6313\n",
      "Epoch 30/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.3035 - precision: 0.6915 - recall: 0.7112 - val_accuracy: 0.7936 - val_loss: 0.3888 - val_precision: 0.6157 - val_recall: 0.6402\n",
      "Epoch 31/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.3016 - precision: 0.6927 - recall: 0.7135 - val_accuracy: 0.7927 - val_loss: 0.3905 - val_precision: 0.6142 - val_recall: 0.6380\n",
      "Epoch 32/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.2998 - precision: 0.6957 - recall: 0.7158 - val_accuracy: 0.7942 - val_loss: 0.3893 - val_precision: 0.6180 - val_recall: 0.6358\n",
      "Epoch 33/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 0.2981 - precision: 0.6973 - recall: 0.7206 - val_accuracy: 0.7948 - val_loss: 0.3941 - val_precision: 0.6159 - val_recall: 0.6512\n",
      "Epoch 34/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8456 - loss: 0.2971 - precision: 0.7027 - recall: 0.7226 - val_accuracy: 0.7951 - val_loss: 0.3898 - val_precision: 0.6180 - val_recall: 0.6446\n",
      "Epoch 35/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8466 - loss: 0.2953 - precision: 0.7030 - recall: 0.7285 - val_accuracy: 0.7948 - val_loss: 0.3926 - val_precision: 0.6156 - val_recall: 0.6523\n",
      "Epoch 36/60\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.2936 - precision: 0.7060 - recall: 0.7268 - val_accuracy: 0.7960 - val_loss: 0.3913 - val_precision: 0.6187 - val_recall: 0.6501\n",
      "\n",
      "Últimos valores de métricas en entrenamiento:\n",
      "        loss  val_loss  accuracy  val_accuracy  precision  val_precision  \\\n",
      "35  0.293571  0.391278  0.847539       0.79598   0.706028       0.618697   \n",
      "\n",
      "      recall  val_recall  \n",
      "35  0.726835     0.65011  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Dejo fija la semilla para que el entrenamiento sea replicable\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Dimensión de entrada = número de features escaladas\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "print(\"Dimensión de entrada del modelo de clasificación:\", input_dim)\n",
    "\n",
    "# Armo un MLP sencillo como baseline para clasificación binaria\n",
    "modelo_clf = tf.keras.Sequential()\n",
    "modelo_clf.add(tf.keras.layers.InputLayer(input_shape=(input_dim,)))\n",
    "modelo_clf.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "modelo_clf.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "modelo_clf.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))  # salida en [0,1] para probabilidad de recommended\n",
    "\n",
    "modelo_clf.summary()\n",
    "\n",
    "# Para clasificación binaria:\n",
    "# - loss: binary_crossentropy\n",
    "# - optimizer: adam (funciona bien por defecto)\n",
    "# - métricas: accuracy + precision + recall para ver balance\n",
    "modelo_clf.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Early stopping para no sobreentrenar cuando la val_loss deje de mejorar\n",
    "early_stop_clf = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entreno el modelo con un 20% del train como validación interna\n",
    "history_clf = modelo_clf.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop_clf],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardo el historial en un DataFrame si luego quiero graficar\n",
    "import pandas as pd\n",
    "\n",
    "hist_clf = pd.DataFrame(history_clf.history)\n",
    "hist_clf[\"epoch\"] = history_clf.epoch\n",
    "\n",
    "print(\"\\nÚltimos valores de métricas en entrenamiento:\")\n",
    "print(hist_clf.tail(1)[[\"loss\", \"val_loss\", \"accuracy\", \"val_accuracy\", \"precision\", \"val_precision\", \"recall\", \"val_recall\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
